# -*- coding: utf-8 -*-
"""Sentiment Analysis of Restaurant Reviews .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OVtN12FXW2uCOSu7uQyZN8YW9TAru39p

# **Sentiment Analysis of Restaurant Reviews with NLP**
"""

# Importing necessary libraries
import numpy as np
import pandas as pd

# Load the dataset from the specified file path using '\t' (tab) as the delimiter
dataset = pd.read_csv('/content/Restaurant_Reviews (1).tsv', delimiter='\t')

dataset.head()

dataset.shape

dataset.size

dataset.describe()

dataset.dtypes

dataset.nunique()

# library to clean data
import re

# Natural Language Tool Kit
import nltk

nltk.download('stopwords')

# to remove stopword
from nltk.corpus import stopwords

# for Stemming propose
from nltk.stem.porter import PorterStemmer

# Initialize empty array
# to append clean text
corpus = []

# 1000 (reviews) rows to clean
for i in range(0, 1000):

	# column : "Review", row ith
	review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])

	# convert all cases to lower cases
	review = review.lower()

	# split to array(default delimiter is " ")
	review = review.split()

	# creating PorterStemmer object to
	# take main stem of each word
	ps = PorterStemmer()

	# loop for stemming each word
	# in string array at ith row
	review = [ps.stem(word) for word in review
				if not word in set(stopwords.words('english'))]

	# rejoin all string array elements
	# to create back into a string
	review = ' '.join(review)

	# append each string to create
	# array of clean text
	corpus.append(review)

# Creating the Bag of Words model
from sklearn.feature_extraction.text import CountVectorizer

# To extract max 1500 feature.
# experiment with to get better results
cv = CountVectorizer(max_features = 1500)

# X contains corpus (dependent variable)
X = cv.fit_transform(corpus).toarray()

# y contains answers if review
# is positive or negative
y = dataset.iloc[:, 1].values

# Importing necessary libraries
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming cm is a valid confusion matrix
cm = [[72, 25], [22, 81]]

# Creating a figure for the heatmap with specified size
plt.figure(figsize=(10, 6))

# Creating a heatmap using seaborn, annot=True displays the values in each cell
# cmap specifies the color palette, xticklabels and yticklabels set the labels for x and y axis
sns.heatmap(cm, annot=True, cmap="Reds", xticklabels=['Negative','Positive'], yticklabels=['Negative','Positive'])

# Setting the label for x-axis and y-axis
plt.xlabel('Predicted Values')
plt.ylabel('Actual Values')

# Displaying the plot
plt.show()

# Splitting the dataset into
# the Training set and Test set
from sklearn.model_selection import train_test_split

# experiment with "test_size"
# to get better results
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)

# Fitting Random Forest Classification
# to the Training set
from sklearn.ensemble import RandomForestClassifier

# n_estimators can be said as number of
# trees, experiment with n_estimators
# to get better results
model = RandomForestClassifier(n_estimators = 501,
							criterion = 'entropy')

model.fit(X_test, y_test)

# Fitting Random Forest Classification
# to the Training set
from sklearn.ensemble import RandomForestClassifier

# n_estimators can be said as number of
# trees, experiment with n_estimators
# to get better results
model = RandomForestClassifier(n_estimators = 601,
							criterion = 'entropy')

model.fit(X_train, y_train)

# Predicting the Test set results
y_pred = model.predict(X_train)
print(y_pred)

# Predicting the Test set results Accuracy
acc = round(model.score(X_train,y_train)*100,2)
print(str(acc)+'%')

# Predicting the Test set results Accuracy
acc = round(model.score(X_test,y_test)*100,2)
print(str(acc)+'%')

# Import necessary libraries
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder

# Initialize ColumnTransformer with OneHotEncoder for column at index 1
ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')

# Transform the input data 'X'
X = np.array(ct.fit_transform(X))

# 'X' now contains the transformed data

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0)

X_train.shape, X_test.shape, y_train.shape, y_test.shape

# Importing the LinearRegression class from the sklearn.linear_model module
from sklearn.linear_model import LinearRegression

# Creating an instance of the LinearRegression class
regressor = LinearRegression()

# Training the regression model using the training data X_train and y_train
regressor.fit(X_train, y_train)

# Predicting the target variable using the trained regressor model
y_pred = regressor.predict(X_test)

# Setting the precision of floating-point numbers for printing
np.set_printoptions(precision=2)

# Concatenating the predicted values (y_pred) and the actual values (y_test) for comparison
result = np.concatenate((y_pred.reshape(len(y_pred), 1), y_test.reshape(len(y_test), 1)), 1)

# Printing the concatenated array
print(result)

# Import necessary modules
from sklearn import metrics
from sklearn.metrics import mean_squared_error

import numpy as np

# Assuming y_test and y_pred are already defined earlier in your code

# Calculate and print Mean Absolute Error (MAE)
mae = metrics.mean_absolute_error(y_test, y_pred)
print("MAE", mae)

# Calculate and print Mean Squared Error (MSE)
mse = mean_squared_error(y_test, y_pred)
print("MSE", mse)

# Calculate and print Root Mean Squared Error (RMSE)
rmse = np.sqrt(mse)
print("RMSE", rmse)

import csv

# Define the file path
file_path = '/content/Restaurant_Reviews (1).tsv'

data = []

# Open the TSV file using 'with' statement
with open(file_path, 'r', newline='', encoding='utf-8') as tsvfile:
    # Create a CSV reader object with tab as the delimiter
    reader = csv.reader(tsvfile, delimiter='\t')

    # Iterate through the rows in the TSV file and append them to the 'data' list
    for row in reader:
        data.append(row)

# Assuming the data is organized as rows, you can print it
for row in data:
    print(row)

import re  # Import the regular expression module
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer

# Define a function named 'predict_sentiment' that takes a 'sample_review' as input
def predict_sentiment(sample_review):
  # Remove non-alphabetic characters from the 'sample_review'
  sample_review = re.sub(pattern='[^a-zA-Z]', repl='', string=sample_review)

  # Convert the 'sample_review' to lowercase
  sample_review = sample_review.lower()

  # Split the 'sample_review' into a list of words
  sample_review_words = sample_review.split()

  # Remove English stopwords from the list of words
  sample_review_words = [word for word in sample_review_words if not word in set(stopwords.words("english"))]

  # Initialize a Porter Stemmer
  ps = PorterStemmer()

  # Apply stemming to each word in the list of words
  final_review = [ps.stem(word) for word in sample_review_words]

  # Join the stemmed words back into a single string
  final_review = ''.join(final_review)

  # Transform the final_review using the CountVectorizer 'cv' and convert it to an array
  temp = cv.transform([final_review]).toarray()

  # Return the prediction for the sentiment of the review using the Classifier
  return Classifier.predict(temp)

# Import libraries
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB

# Sample data for training
texts = [
    'This is a positive review',
    'I really enjoyed the movie',
    'The food was amazing',
    'I did not like the service',
    'The product is terrible'
]
labels = ['positive', 'positive', 'positive', 'negative', 'negative']

# Initialize and train the vectorizer
vectorizer = CountVectorizer()
X_train = vectorizer.fit_transform(texts)

# Initialize and train the classifier
classifier = MultinomialNB()
classifier.fit(X_train, labels)

def predict_sentiment(text):
    text_vectorized = vectorizer.transform([text])
    prediction = classifier.predict(text_vectorized)
    return prediction[0]

# Prediciting Review
sample_review = 'I really enjoyed the movie'

if predict_sentiment(sample_review) == 'positive':
    print('This is a Positive review')
else:
    print('This is a Negative review')

# Predicting Review
sample_review = 'The food was amazing'

if predict_sentiment(sample_review) == 'positive':
    print('This is a Positive review')
else:
    print('This is a Negative review!')

# Predicting Review
sample_review = 'I did not like the service'

if predict_sentiment(sample_review) == 'positive':
    print('This is a Positive review')
else:
    print('This is a Negative review!')

# Predicting Review
sample_review = 'The product is terrible'

if predict_sentiment(sample_review) == 'positive':
    print('This is a Positive review')
else:
    print('This is a Negative review!')

